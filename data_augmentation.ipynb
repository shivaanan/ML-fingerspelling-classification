{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install tensorflow-datasets\n",
    "# !pip install seaborn\n",
    "# !pip install scikit-image\n",
    "# !pip install skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CajVlVZ3UsFN"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import string \n",
    "import random\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import seaborn as sns\n",
    "from keras import layers\n",
    "import keras\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NvWhS0wZU4xI",
    "outputId": "05fee4a3-6b19-4f4a-98c8-f32bb5fd6e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "90Q_HBAsYvl-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "\n",
    "def get_labels_images(path):\n",
    "    labels = []\n",
    "    images = []\n",
    "    directories = []\n",
    "    for directory in os.listdir(path):\n",
    "        if os.path.isdir(os.path.join(path, directory)):  # Check if it's a directory\n",
    "            for Label in os.listdir(os.path.join(path, directory)):\n",
    "                if os.path.isdir(os.path.join(path, directory, Label)):  # Check if it's a directory\n",
    "                    for Image in os.listdir(os.path.join(path, directory, Label)):\n",
    "                        directories.append(directory)\n",
    "                        labels.append(Label)\n",
    "                        images.append(directory + '/' + Label + '/' + Image)\n",
    "    return pd.DataFrame({'directories': directories, 'labels': labels, 'images': images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "NnVOcC1AYsSC",
    "outputId": "ea985016-d8fa-4dc0-df70-2bdcfb0c6217"
   },
   "outputs": [],
   "source": [
    "base_path = \"./dataset\"\n",
    "df = get_labels_images(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df = df.sort_values(by=['labels'])\n",
    "# alphabet_labels = np.array(list(string.ascii_lowercase))\n",
    "# print_labels = np.array(temp_df['labels'].unique())\n",
    "# set_diff = np.setdiff1d(alphabet_labels, print_labels)\n",
    "# print(print_labels)\n",
    "# print(\"Missing Letters:\",set_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display an image\n",
    "# image_path = os.path.join(base_path, \"A/a/color_0_0002.png\")\n",
    "# image = imread(image_path)\n",
    "# plt.imshow(image)\n",
    "# plt.title(\"Original Image\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def random_sample_plot(X, base_path):\n",
    "#     plt.figure(figsize=(15, 18))\n",
    "#     for i in range(16):\n",
    "#         plt.subplot(4, 4, i+1)\n",
    "#         sample = random.choice(X['images'])\n",
    "#         image = load_img(base_path+'/'+sample, target_size=(64,64))\n",
    "#         plt.imshow(image)\n",
    "#         plt.title(\"label:{},\\nimage:{}\".format(X[X['images']==sample]['labels'].values[0], sample))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random_sample_plot(df, base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_df = df[df['images'].map(\n",
    "#     lambda x: True if x.find('color')!=-1 else False)].reset_index(drop=True)\n",
    "# deep_df = df[df['images'].map(\n",
    "#     lambda x: True if x.find('color')==-1 else False)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random_sample_plot(color_df, base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random_sample_plot(deep_df, base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def plot_data(data):\n",
    "#     fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,10))\n",
    "#     ax1.set_title('Bar Graph Count of Letter Signs')\n",
    "#     ax2.set_title('Pie Chart Graph Count of Letter Signs')\n",
    "#     sns.countplot(x=data['labels'], ax=ax1)\n",
    "#     data['labels'].value_counts().plot.pie(autopct='%1.1f%%',shadow=False,textprops={'fontsize': 15},ax=ax2)\n",
    "#     plt.show()\n",
    "    \n",
    "# plot_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Don't need this\n",
    "# Keras Sequential model\n",
    "# Resize and rescale to 180 x 180 using keras\n",
    "\n",
    "\n",
    "\n",
    "# IMG_SIZE = 180\n",
    "\n",
    "# sample = random.choice(df['images'])\n",
    "# image = load_img(base_path+'/'+sample,target_size=(64,64))\n",
    "# plt.imshow(image)\n",
    "# plt.show()\n",
    "\n",
    "# resize_and_rescale = keras.Sequential([\n",
    "#   layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "#   layers.Rescaling(1./255)\n",
    "# ])\n",
    "\n",
    "# result = resize_and_rescale(image)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(result);\n",
    "# print(\"Rescaled image of\", sample, \"to 180 x 180\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't need this\n",
    "# flipping images using keras\n",
    "\n",
    "\n",
    "# data_augmentation = keras.Sequential([\n",
    "#   layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "#   layers.RandomRotation(0.4),\n",
    "# ])\n",
    "\n",
    "# plt.imshow(image)\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(8, 7))\n",
    "# for i in range(6):\n",
    "#   augmented_image = data_augmentation(image)\n",
    "#   ax = plt.subplot(2, 3, i + 1)\n",
    "#   plt.imshow(augmented_image.numpy()/255)\n",
    "#   plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "def add_gaussian_noise(image):\n",
    "    \"\"\"Add Gaussian noise to an image.\"\"\"\n",
    "    row, col, _ = image.shape\n",
    "    mean = 0\n",
    "    var = 25  # Adjusted for images in [0, 255] range\n",
    "    sigma = var**0.5\n",
    "    gauss = np.random.normal(mean, sigma, (row, col, 1))\n",
    "    gauss = gauss.reshape(row, col, -1)\n",
    "    noisy = image + gauss\n",
    "    return np.clip(noisy, 0, 255)\n",
    "\n",
    "# For RGB images\n",
    "color_datagen = ImageDataGenerator(\n",
    "    #... [your parameters here]\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    preprocessing_function=add_gaussian_noise\n",
    ")\n",
    "\n",
    "# For depth images (no brightness adjustment)\n",
    "depth_datagen = ImageDataGenerator(\n",
    "    #... [your parameters here]\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=add_gaussian_noise\n",
    ")\n",
    "\n",
    "# this mean i will get 3x of each file (so both depth and RGB will give 6X)\n",
    "num_augmented_images = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = [\"A\",\"B\",\"C\",\"D\",\"E\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v\n",
      "./dataset/A/v ./augmented_images/A/v\n",
      "p\n",
      "./dataset/A/p ./augmented_images/A/p\n",
      "d\n",
      "./dataset/A/d ./augmented_images/A/d\n",
      "t\n",
      "./dataset/A/t ./augmented_images/A/t\n",
      "l\n",
      "./dataset/A/l ./augmented_images/A/l\n",
      "e\n",
      "./dataset/A/e ./augmented_images/A/e\n",
      "q\n",
      "./dataset/A/q ./augmented_images/A/q\n",
      "u\n",
      "./dataset/A/u ./augmented_images/A/u\n",
      "m\n",
      "./dataset/A/m ./augmented_images/A/m\n",
      "i\n",
      "./dataset/A/i ./augmented_images/A/i\n",
      "h\n",
      "./dataset/A/h ./augmented_images/A/h\n",
      "g\n",
      "./dataset/A/g ./augmented_images/A/g\n",
      "c\n",
      "./dataset/A/c ./augmented_images/A/c\n",
      "b\n",
      "./dataset/A/b ./augmented_images/A/b\n",
      "o\n",
      "./dataset/A/o ./augmented_images/A/o\n",
      "f\n",
      "./dataset/A/f ./augmented_images/A/f\n",
      "n\n",
      "./dataset/A/n ./augmented_images/A/n\n",
      "w\n",
      "./dataset/A/w ./augmented_images/A/w\n",
      "x\n",
      "./dataset/A/x ./augmented_images/A/x\n",
      "s\n",
      "./dataset/A/s ./augmented_images/A/s\n",
      "a\n",
      "./dataset/A/a ./augmented_images/A/a\n",
      "r\n",
      "./dataset/A/r ./augmented_images/A/r\n",
      "y\n",
      "./dataset/A/y ./augmented_images/A/y\n",
      "k\n",
      "./dataset/A/k ./augmented_images/A/k\n"
     ]
    }
   ],
   "source": [
    "# Set this to person A only\n",
    "input_directory = './dataset/A'\n",
    "output_directory = './augmented_images/A'\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate through folders a to z\n",
    "for folder_name in os.listdir(os.path.join(input_directory)):\n",
    "    print(folder_name)\n",
    "    folder_path = os.path.join(input_directory, folder_name)\n",
    "    output_folder_path = os.path.join(output_directory, folder_name)\n",
    "    print(folder_path, output_folder_path)\n",
    "    os.makedirs(output_folder_path, exist_ok=True)\n",
    "    \n",
    "    image_counter = 0\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        color_image_files = [file for file in os.listdir(folder_path) if file.endswith(('png')) and 'color' in file]\n",
    "        \n",
    "        for color_img_name in color_image_files:\n",
    "            # This code limit the augmentation to 50 per file (a,b,c,d,...)\n",
    "            if image_counter >= 200:\n",
    "                break\n",
    "            \n",
    "            color_img_path = os.path.join(folder_path, color_img_name)\n",
    "            \n",
    "            # Find corresponding depth image\n",
    "            depth_img_name = color_img_name.replace('color', 'depth')\n",
    "            depth_img_path = os.path.join(folder_path, depth_img_name)\n",
    "            \n",
    "            # Load images\n",
    "            try:\n",
    "                color_img = load_img(color_img_path)\n",
    "                depth_img = load_img(depth_img_path)\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"Error loading images: {e}\")\n",
    "                continue\n",
    "\n",
    "            #... [Rest of your image processing code]\n",
    "            color_x = img_to_array(color_img).reshape((1,) + img_to_array(color_img).shape)\n",
    "            depth_x = img_to_array(depth_img).reshape((1,) + img_to_array(depth_img).shape)\n",
    "\n",
    "            # Generate augmented images in pairs\n",
    "            for i in range(num_augmented_images):\n",
    "                color_batch = next(color_datagen.flow(color_x, batch_size=1))\n",
    "                depth_batch = next(depth_datagen.flow(depth_x, batch_size=1))\n",
    "\n",
    "                # Convert augmented images back from array to image format\n",
    "                color_augmented_img = array_to_img(color_batch[0])\n",
    "                depth_augmented_img = array_to_img(depth_batch[0])\n",
    "                \n",
    "                base_filename = os.path.splitext(os.path.basename(color_img_path))[0]\n",
    "                color_augmented_img.save(os.path.join(output_folder_path, f'{base_filename}_augmented_{i + 1}.png'))\n",
    "                depth_augmented_img.save(os.path.join(output_folder_path, f'{base_filename.replace(\"color\", \"depth\")}_augmented_{i + 1}.png'))\n",
    "            \n",
    "            image_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v\n",
      "./dataset/B/v ./augmented_images/B/v\n",
      "p\n",
      "./dataset/B/p ./augmented_images/B/p\n",
      "d\n",
      "./dataset/B/d ./augmented_images/B/d\n",
      "t\n",
      "./dataset/B/t ./augmented_images/B/t\n",
      "l\n",
      "./dataset/B/l ./augmented_images/B/l\n",
      "e\n",
      "./dataset/B/e ./augmented_images/B/e\n",
      "q\n",
      "./dataset/B/q ./augmented_images/B/q\n",
      "u\n",
      "./dataset/B/u ./augmented_images/B/u\n",
      "m\n",
      "./dataset/B/m ./augmented_images/B/m\n",
      "i\n",
      "./dataset/B/i ./augmented_images/B/i\n",
      "h\n",
      "./dataset/B/h ./augmented_images/B/h\n",
      "g\n",
      "./dataset/B/g ./augmented_images/B/g\n",
      "c\n",
      "./dataset/B/c ./augmented_images/B/c\n",
      "b\n",
      "./dataset/B/b ./augmented_images/B/b\n",
      "o\n",
      "./dataset/B/o ./augmented_images/B/o\n",
      "f\n",
      "./dataset/B/f ./augmented_images/B/f\n",
      "n\n",
      "./dataset/B/n ./augmented_images/B/n\n",
      "w\n",
      "./dataset/B/w ./augmented_images/B/w\n",
      "x\n",
      "./dataset/B/x ./augmented_images/B/x\n",
      "s\n",
      "./dataset/B/s ./augmented_images/B/s\n",
      "a\n",
      "./dataset/B/a ./augmented_images/B/a\n",
      "r\n",
      "./dataset/B/r ./augmented_images/B/r\n",
      "y\n",
      "./dataset/B/y ./augmented_images/B/y\n",
      "k\n",
      "./dataset/B/k ./augmented_images/B/k\n"
     ]
    }
   ],
   "source": [
    "# Set this to person A only\n",
    "input_directory = './dataset/B'\n",
    "output_directory = './augmented_images/B'\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate through folders a to z\n",
    "for folder_name in os.listdir(os.path.join(input_directory)):\n",
    "    print(folder_name)\n",
    "    folder_path = os.path.join(input_directory, folder_name)\n",
    "    output_folder_path = os.path.join(output_directory, folder_name)\n",
    "    print(folder_path, output_folder_path)\n",
    "    os.makedirs(output_folder_path, exist_ok=True)\n",
    "    \n",
    "    image_counter = 0\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        color_image_files = [file for file in os.listdir(folder_path) if file.endswith(('png')) and 'color' in file]\n",
    "        \n",
    "        for color_img_name in color_image_files:\n",
    "            # This code limit the augmentation to 50 per file (a,b,c,d,...)\n",
    "            if image_counter >= 200:\n",
    "                break\n",
    "            \n",
    "            color_img_path = os.path.join(folder_path, color_img_name)\n",
    "            \n",
    "            # Find corresponding depth image\n",
    "            depth_img_name = color_img_name.replace('color', 'depth')\n",
    "            depth_img_path = os.path.join(folder_path, depth_img_name)\n",
    "            \n",
    "            # Load images\n",
    "            try:\n",
    "                color_img = load_img(color_img_path)\n",
    "                depth_img = load_img(depth_img_path)\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"Error loading images: {e}\")\n",
    "                continue\n",
    "\n",
    "            #... [Rest of your image processing code]\n",
    "            color_x = img_to_array(color_img).reshape((1,) + img_to_array(color_img).shape)\n",
    "            depth_x = img_to_array(depth_img).reshape((1,) + img_to_array(depth_img).shape)\n",
    "\n",
    "            # Generate augmented images in pairs\n",
    "            for i in range(num_augmented_images):\n",
    "                color_batch = next(color_datagen.flow(color_x, batch_size=1))\n",
    "                depth_batch = next(depth_datagen.flow(depth_x, batch_size=1))\n",
    "\n",
    "                # Convert augmented images back from array to image format\n",
    "                color_augmented_img = array_to_img(color_batch[0])\n",
    "                depth_augmented_img = array_to_img(depth_batch[0])\n",
    "                \n",
    "                base_filename = os.path.splitext(os.path.basename(color_img_path))[0]\n",
    "                color_augmented_img.save(os.path.join(output_folder_path, f'{base_filename}_augmented_{i + 1}.png'))\n",
    "                depth_augmented_img.save(os.path.join(output_folder_path, f'{base_filename.replace(\"color\", \"depth\")}_augmented_{i + 1}.png'))\n",
    "            \n",
    "            image_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set this to person A only\n",
    "# input_directory = './dataset/C'\n",
    "# output_directory = './augmented_images/C'\n",
    "\n",
    "# os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# # Iterate through folders a to z\n",
    "# for folder_name in os.listdir(os.path.join(input_directory)):\n",
    "#     print(folder_name)\n",
    "#     folder_path = os.path.join(input_directory, folder_name)\n",
    "#     output_folder_path = os.path.join(output_directory, folder_name)\n",
    "#     print(folder_path, output_folder_path)\n",
    "#     os.makedirs(output_folder_path, exist_ok=True)\n",
    "    \n",
    "#     image_counter = 0\n",
    "    \n",
    "#     if os.path.isdir(folder_path):\n",
    "#         color_image_files = [file for file in os.listdir(folder_path) if file.endswith(('png')) and 'color' in file]\n",
    "        \n",
    "#         for color_img_name in color_image_files:\n",
    "#             # This code limit the augmentation to 50 per file (a,b,c,d,...)\n",
    "#             if image_counter >= 200:\n",
    "#                 break\n",
    "            \n",
    "#             color_img_path = os.path.join(folder_path, color_img_name)\n",
    "            \n",
    "#             # Find corresponding depth image\n",
    "#             depth_img_name = color_img_name.replace('color', 'depth')\n",
    "#             depth_img_path = os.path.join(folder_path, depth_img_name)\n",
    "            \n",
    "#             # Load images\n",
    "#             try:\n",
    "#                 color_img = load_img(color_img_path)\n",
    "#                 depth_img = load_img(depth_img_path)\n",
    "#             except FileNotFoundError as e:\n",
    "#                 print(f\"Error loading images: {e}\")\n",
    "#                 continue\n",
    "\n",
    "#             #... [Rest of your image processing code]\n",
    "#             color_x = img_to_array(color_img).reshape((1,) + img_to_array(color_img).shape)\n",
    "#             depth_x = img_to_array(depth_img).reshape((1,) + img_to_array(depth_img).shape)\n",
    "\n",
    "#             # Generate augmented images in pairs\n",
    "#             for i in range(num_augmented_images):\n",
    "#                 color_batch = next(color_datagen.flow(color_x, batch_size=1))\n",
    "#                 depth_batch = next(depth_datagen.flow(depth_x, batch_size=1))\n",
    "\n",
    "#                 # Convert augmented images back from array to image format\n",
    "#                 color_augmented_img = array_to_img(color_batch[0])\n",
    "#                 depth_augmented_img = array_to_img(depth_batch[0])\n",
    "                \n",
    "#                 base_filename = os.path.splitext(os.path.basename(color_img_path))[0]\n",
    "#                 color_augmented_img.save(os.path.join(output_folder_path, f'{base_filename}_augmented_{i + 1}.png'))\n",
    "#                 depth_augmented_img.save(os.path.join(output_folder_path, f'{base_filename.replace(\"color\", \"depth\")}_augmented_{i + 1}.png'))\n",
    "            \n",
    "#             image_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v\n",
      "./dataset/D/v ./augmented_images/D/v\n",
      "p\n",
      "./dataset/D/p ./augmented_images/D/p\n",
      "d\n",
      "./dataset/D/d ./augmented_images/D/d\n",
      "t\n",
      "./dataset/D/t ./augmented_images/D/t\n",
      "l\n",
      "./dataset/D/l ./augmented_images/D/l\n",
      "e\n",
      "./dataset/D/e ./augmented_images/D/e\n",
      "q\n",
      "./dataset/D/q ./augmented_images/D/q\n",
      "u\n",
      "./dataset/D/u ./augmented_images/D/u\n",
      "m\n",
      "./dataset/D/m ./augmented_images/D/m\n",
      "i\n",
      "./dataset/D/i ./augmented_images/D/i\n",
      "h\n",
      "./dataset/D/h ./augmented_images/D/h\n",
      "g\n",
      "./dataset/D/g ./augmented_images/D/g\n",
      "c\n",
      "./dataset/D/c ./augmented_images/D/c\n",
      "b\n",
      "./dataset/D/b ./augmented_images/D/b\n",
      "o\n",
      "./dataset/D/o ./augmented_images/D/o\n",
      "f\n",
      "./dataset/D/f ./augmented_images/D/f\n",
      "n\n",
      "./dataset/D/n ./augmented_images/D/n\n",
      "w\n",
      "./dataset/D/w ./augmented_images/D/w\n",
      "x\n",
      "./dataset/D/x ./augmented_images/D/x\n",
      "s\n",
      "./dataset/D/s ./augmented_images/D/s\n",
      "a\n",
      "./dataset/D/a ./augmented_images/D/a\n",
      "r\n",
      "./dataset/D/r ./augmented_images/D/r\n",
      "y\n",
      "./dataset/D/y ./augmented_images/D/y\n",
      "k\n",
      "./dataset/D/k ./augmented_images/D/k\n"
     ]
    }
   ],
   "source": [
    "# Set this to person A only\n",
    "input_directory = './dataset/D'\n",
    "output_directory = './augmented_images/D'\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate through folders a to z\n",
    "for folder_name in os.listdir(os.path.join(input_directory)):\n",
    "    print(folder_name)\n",
    "    folder_path = os.path.join(input_directory, folder_name)\n",
    "    output_folder_path = os.path.join(output_directory, folder_name)\n",
    "    print(folder_path, output_folder_path)\n",
    "    os.makedirs(output_folder_path, exist_ok=True)\n",
    "    \n",
    "    image_counter = 0\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        color_image_files = [file for file in os.listdir(folder_path) if file.endswith(('png')) and 'color' in file]\n",
    "        \n",
    "        for color_img_name in color_image_files:\n",
    "            # This code limit the augmentation to 50 per file (a,b,c,d,...)\n",
    "            if image_counter >= 200:\n",
    "                break\n",
    "            \n",
    "            color_img_path = os.path.join(folder_path, color_img_name)\n",
    "            \n",
    "            # Find corresponding depth image\n",
    "            depth_img_name = color_img_name.replace('color', 'depth')\n",
    "            depth_img_path = os.path.join(folder_path, depth_img_name)\n",
    "            \n",
    "            # Load images\n",
    "            try:\n",
    "                color_img = load_img(color_img_path)\n",
    "                depth_img = load_img(depth_img_path)\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"Error loading images: {e}\")\n",
    "                continue\n",
    "\n",
    "            #... [Rest of your image processing code]\n",
    "            color_x = img_to_array(color_img).reshape((1,) + img_to_array(color_img).shape)\n",
    "            depth_x = img_to_array(depth_img).reshape((1,) + img_to_array(depth_img).shape)\n",
    "\n",
    "            # Generate augmented images in pairs\n",
    "            for i in range(num_augmented_images):\n",
    "                color_batch = next(color_datagen.flow(color_x, batch_size=1))\n",
    "                depth_batch = next(depth_datagen.flow(depth_x, batch_size=1))\n",
    "\n",
    "                # Convert augmented images back from array to image format\n",
    "                color_augmented_img = array_to_img(color_batch[0])\n",
    "                depth_augmented_img = array_to_img(depth_batch[0])\n",
    "                \n",
    "                base_filename = os.path.splitext(os.path.basename(color_img_path))[0]\n",
    "                color_augmented_img.save(os.path.join(output_folder_path, f'{base_filename}_augmented_{i + 1}.png'))\n",
    "                depth_augmented_img.save(os.path.join(output_folder_path, f'{base_filename.replace(\"color\", \"depth\")}_augmented_{i + 1}.png'))\n",
    "            \n",
    "            image_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v\n",
      "./dataset/E/v ./augmented_images/E/v\n",
      "p\n",
      "./dataset/E/p ./augmented_images/E/p\n",
      "d\n",
      "./dataset/E/d ./augmented_images/E/d\n",
      "t\n",
      "./dataset/E/t ./augmented_images/E/t\n",
      "l\n",
      "./dataset/E/l ./augmented_images/E/l\n",
      "e\n",
      "./dataset/E/e ./augmented_images/E/e\n",
      "q\n",
      "./dataset/E/q ./augmented_images/E/q\n",
      "u\n",
      "./dataset/E/u ./augmented_images/E/u\n",
      "m\n",
      "./dataset/E/m ./augmented_images/E/m\n",
      "i\n",
      "./dataset/E/i ./augmented_images/E/i\n",
      "h\n",
      "./dataset/E/h ./augmented_images/E/h\n",
      "g\n",
      "./dataset/E/g ./augmented_images/E/g\n",
      "c\n",
      "./dataset/E/c ./augmented_images/E/c\n",
      "b\n",
      "./dataset/E/b ./augmented_images/E/b\n",
      "o\n",
      "./dataset/E/o ./augmented_images/E/o\n",
      "f\n",
      "./dataset/E/f ./augmented_images/E/f\n",
      "n\n",
      "./dataset/E/n ./augmented_images/E/n\n",
      "w\n",
      "./dataset/E/w ./augmented_images/E/w\n",
      "x\n",
      "./dataset/E/x ./augmented_images/E/x\n",
      "s\n",
      "./dataset/E/s ./augmented_images/E/s\n",
      "a\n",
      "./dataset/E/a ./augmented_images/E/a\n",
      "r\n",
      "./dataset/E/r ./augmented_images/E/r\n",
      "y\n",
      "./dataset/E/y ./augmented_images/E/y\n",
      "k\n",
      "./dataset/E/k ./augmented_images/E/k\n"
     ]
    }
   ],
   "source": [
    "# Set this to person A only\n",
    "input_directory = './dataset/E'\n",
    "output_directory = './augmented_images/E'\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate through folders a to z\n",
    "for folder_name in os.listdir(os.path.join(input_directory)):\n",
    "    print(folder_name)\n",
    "    folder_path = os.path.join(input_directory, folder_name)\n",
    "    output_folder_path = os.path.join(output_directory, folder_name)\n",
    "    print(folder_path, output_folder_path)\n",
    "    os.makedirs(output_folder_path, exist_ok=True)\n",
    "    \n",
    "    image_counter = 0\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        color_image_files = [file for file in os.listdir(folder_path) if file.endswith(('png')) and 'color' in file]\n",
    "        \n",
    "        for color_img_name in color_image_files:\n",
    "            # This code limit the augmentation to 50 per file (a,b,c,d,...)\n",
    "            if image_counter >= 200:\n",
    "                break\n",
    "            \n",
    "            color_img_path = os.path.join(folder_path, color_img_name)\n",
    "            \n",
    "            # Find corresponding depth image\n",
    "            depth_img_name = color_img_name.replace('color', 'depth')\n",
    "            depth_img_path = os.path.join(folder_path, depth_img_name)\n",
    "            \n",
    "            # Load images\n",
    "            try:\n",
    "                color_img = load_img(color_img_path)\n",
    "                depth_img = load_img(depth_img_path)\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"Error loading images: {e}\")\n",
    "                continue\n",
    "\n",
    "            #... [Rest of your image processing code]\n",
    "            color_x = img_to_array(color_img).reshape((1,) + img_to_array(color_img).shape)\n",
    "            depth_x = img_to_array(depth_img).reshape((1,) + img_to_array(depth_img).shape)\n",
    "\n",
    "            # Generate augmented images in pairs\n",
    "            for i in range(num_augmented_images):\n",
    "                color_batch = next(color_datagen.flow(color_x, batch_size=1))\n",
    "                depth_batch = next(depth_datagen.flow(depth_x, batch_size=1))\n",
    "\n",
    "                # Convert augmented images back from array to image format\n",
    "                color_augmented_img = array_to_img(color_batch[0])\n",
    "                depth_augmented_img = array_to_img(depth_batch[0])\n",
    "                \n",
    "                base_filename = os.path.splitext(os.path.basename(color_img_path))[0]\n",
    "                color_augmented_img.save(os.path.join(output_folder_path, f'{base_filename}_augmented_{i + 1}.png'))\n",
    "                depth_augmented_img.save(os.path.join(output_folder_path, f'{base_filename.replace(\"color\", \"depth\")}_augmented_{i + 1}.png'))\n",
    "            \n",
    "            image_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
